{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Challenge (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, test, optimize, and analyze the performance of a classification model using a methodology of your choice for the randomly generated moons dataset.\n",
    "\n",
    "You are not being evaluated for the performance of your model. Instead, we are interested in whether you can implement a simple but rigorous ML workflow.\n",
    "\n",
    "Show all of your work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,  f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "from sklearn.datasets import make_moons\n",
    "dataset= make_moons\n",
    "X, Y = make_moons(random_state=42, n_samples=(50, 450), noise=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 0 1]\n",
      "96.8\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.25, random_state = 42)\n",
    "'''print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)'''\n",
    "\n",
    "#training with SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#Calculate accuracy of model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing / Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1]\n",
      "Logistic Regression accuracy score: 0.944\n",
      "accuracy_score: 0.944\n",
      "recall: 0.9824561403508771\n",
      "f1_score: <function f1_score at 0x000001F1D8615C10>\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "#Algorithm 1= Logistic Regression\n",
    "lr= LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr= lr.predict(X_test)\n",
    "print('Logistic Regression prediction:', pred_lr)\n",
    "print('Logistic Regression accuracy score:', accuracy_score(y_test, pred_lr))\n",
    "\n",
    "accurate= accuracy_score(y_test,pred_lr)\n",
    "recall= recall_score(y_test,pred_lr, average=\"binary\", pos_label= 1)\n",
    "#f1_score= f1_score(y_test,pred_lr, pos_label=1)\n",
    "print('accuracy_score:', accurate)\n",
    "print('recall:', recall)\n",
    "print('f1_score:', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 1 1]\n",
      "Decision tree accuracy score: 0.96\n"
     ]
    }
   ],
   "source": [
    "#Algorithm 2= Decision Tree\n",
    "dt= DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "pred_dt= dt.predict(X_test)\n",
    "print('Decision tree prediction:', pred_dt)\n",
    "print('Decision tree accuracy score:', accuracy_score(y_test, pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 0 1]\n",
      "Random Forest accuracy score: 0.968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Algorithm 3= Random Forest\n",
    "rf= RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf= rf.predict(X_test)\n",
    "print('Random Forest prediction:', pred_rf)\n",
    "print('Random Forest accuracy score:', accuracy_score(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1]\n",
      "kNN accuracy score: 0.96\n",
      "GaussianNB prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1]\n",
      "GaussianNB score: 0.96\n",
      "0.968\n"
     ]
    }
   ],
   "source": [
    "#Algorithm 4= kNN\n",
    "n=15\n",
    "KNN=KNeighborsClassifier(n_neighbors=n)\n",
    "KNN.fit(X_train,y_train)\n",
    "pred_knn=KNN.predict(X_test)\n",
    "print('kNN prediction:', pred_knn)\n",
    "print('kNN accuracy score:', accuracy_score(y_test, pred_knn))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb= GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "pred_gnb= gnb.predict(X_test)\n",
    "print('GaussianNB prediction:', pred_gnb)\n",
    "print('GaussianNB score:', accuracy_score(y_test, pred_knn))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM algorithm accuracy(in %): 96.8\n",
      "Logistic Regression model accuracy(in %): 94.39999999999999\n",
      "Random Forest model accuracy(in %): 94.39999999999999\n",
      "Decision tree model accuracy(in %): 96.0\n",
      "Gaussian Naive Bayes model accuracy(in %): 96.8\n",
      "[[ 26  13]\n",
      " [ 18 318]]\n",
      "For KNN algo:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.63        39\n",
      "           1       0.96      0.95      0.95       336\n",
      "\n",
      "    accuracy                           0.92       375\n",
      "   macro avg       0.78      0.81      0.79       375\n",
      "weighted avg       0.92      0.92      0.92       375\n",
      "\n",
      "For SVM algo:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.97      0.44        39\n",
      "           1       1.00      0.71      0.83       336\n",
      "\n",
      "    accuracy                           0.74       375\n",
      "   macro avg       0.64      0.84      0.64       375\n",
      "weighted avg       0.92      0.74      0.79       375\n",
      "\n",
      "Precision: 0.9607250755287009  Recall:0.9464285714285714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9535232383808097"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"SVM algorithm accuracy(in %):\", metrics.accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Logistic Regression model accuracy(in %):\", metrics.accuracy_score(y_test, pred_lr)*100)\n",
    "print('Random Forest model accuracy(in %):', metrics.accuracy_score(y_test, pred_lr)*100)\n",
    "print('Decision tree model accuracy(in %):', metrics.accuracy_score(y_test, pred_dt)*100)\n",
    "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "\n",
    "pred = gnb.predict(X_train)\n",
    "print(confusion_matrix(y_train,pred))\n",
    "print('For KNN algo: ', classification_report(y_train, pred))\n",
    "pred2 = svm.predict(X_train)\n",
    "print('For SVM algo: ', classification_report(y_train, pred2))\n",
    "\n",
    "pre = precision_score(y_train, pred)\n",
    "re  = recall_score(y_train, pred)\n",
    "print(f\"Precision: {pre}  Recall:{re}\")\n",
    "f1_score(y_train, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make_moons dataset is a binary dataset. I first split up the X and y variables for training and validating, and then for each step thereafter, I tried 5 different machine learning models to check which algorithm worked best\n",
    "with the given dataset. Then, I evaluated the prediction with sklearnâ€™s classification_report and confusion_matrix, \n",
    "which gave a breakdown of the scores 2 best performing algorithms. Precision and recall are some other metrics that I used to get a better representation of how each algorithm performed.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e78b6b4158d8f577a77be3bef6c4f5889b406541923fa59adc2e6c48950512fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
